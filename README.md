# ğŸ›¡ï¸ Vocal Firewall - Extremist Speech Detection

**Team NameError | Junction X Hackathon**

An automated system for detecting extremist speech in audio files, providing timestamped analysis of potentially harmful content.

## ğŸš€ Quick Start
### 1. Install PyTorch
```bash
# For CUDA 12.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# For CUDA 12.9
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129

# For CPU only (fallback)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 2. Use the quickstart.sh script to set up the project
```bash
chmod +x quickstart.sh
./quickstart.sh
```

### 3. Run the Application

**Terminal 1 - Run API Server:**
```bash
chmod +x run_api.sh
./run_api.sh
```
API docs: http://localhost:8000/docs

**Terminal 2 - Run Frontend:**
```bash
python run_frontend.py
```
Open browser to: http://localhost:8080

**OR - Use CLI for Research:**
```bash
# Check API health
./vfw health

# Analyze single file
./vfw analyze audio.wav -v

# Screen training data directory
./vfw screen ./training_data/

# See full CLI documentation
cat CLI_README.md
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Frontend  â”‚         â”‚   CLI Tool      â”‚
â”‚  (Port 8080)    â”‚         â”‚  (Research)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ REST API
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                â”‚ FastAPI  â”‚ â† Backend Server (Port 8000)
                â”‚  Server  â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                     â”‚
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ ML Pipeline     â”‚
                â”‚ 1. Whisper STT  â”‚ â† Speech-to-Text
                â”‚ 2. Classifier   â”‚ â† Content Classification
                â”‚ 3. Timestamps   â”‚ â† Segment Extraction
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Two Interfaces, Two Audiences

### ğŸŒ Web UI - For General Users
- **Purpose**: Screen materials children may be exposed to
- **Use cases**: Parents, educators, content moderators
- **Features**: Drag & drop, visual results, easy to use

### ğŸ–¥ï¸ CLI - For Researchers
- **Purpose**: Screen training data for speech models
- **Use cases**: ML researchers, dataset curation, automation
- **Features**: Batch processing, CSV/JSON export, filtering, reports
- **Documentation**: See [CLI_README.md](CLI_README.md)

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ index.html               # Web UI
â”œâ”€â”€ app.js                   # Frontend logic
â”œâ”€â”€ run_frontend.py          # Frontend server
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ ensemble_config.yaml     # Model configuration
â”œâ”€â”€ quickstart.sh            # Setup script (Linux/Mac)
â”œâ”€â”€ run_api.sh               # Launch API
â”œâ”€â”€ SETUP.md                 # Detailed setup guide
â”‚
â”œâ”€â”€ vfw_cli.py               # CLI tool (main script)
â”œâ”€â”€ vfw                      # CLI wrapper script
â”œâ”€â”€ CLI_README.md            # CLI documentation
â”œâ”€â”€ CLI_EXAMPLES.md          # CLI usage examples
â”‚
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ config.py            # Application settings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                 # REST API
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI endpoints
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ model/               # ML Models
â”‚   â”‚   â”œâ”€â”€ ensemble.py      # Ensemble orchestrator
â”‚   â”‚   â”œâ”€â”€ text_models.py   # Text classification models
â”‚   â”‚   â”œâ”€â”€ dummy.py         # Test model (dev only)
â”‚   â”‚   â”œâ”€â”€ sentiment_base.py # Base model class
â”‚   â”‚   â””â”€â”€ vibechecker.py   # Audio prosody analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/            # Processing Pipeline
â”‚   â”‚   â”œâ”€â”€ preprocessing.py # Audio preprocessing
â”‚   â”‚   â”œâ”€â”€ transcription.py # Speech-to-text
â”‚   â”‚   â”œâ”€â”€ postprocessing.py # Result assembly
â”‚   â”‚   â”œâ”€â”€ initialize.py    # Model initialization
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ testing/             # Test utilities
|
â”œâ”€â”€ models/                  # Saved model weights
â”‚
â”œâ”€â”€ finetune_ensemble.py     # Model fine-tuning
â”œâ”€â”€ segment_augmentation.py  # Data augmentation
â”‚
â””â”€â”€ temp/                    # Temporary uploads
```

## Acknowledgment of the use of LLMs
- LLMs for coding: Claude 4.5 Sonnet in Cursor and VS Code. Used for quick prototyping, productive quick edits with the tab feature, creating documentation, and refactors
- LLMs for speech: Eleven Labs for voiceover of pitch video
- LLMs for research: ChatGPT for suggestions of useful papers

## ğŸŒ API Endpoints

- `GET /` - Health check
- `GET /health` - Detailed health status
- `POST /analyze` - Analyze single audio file
- `POST /analyze/batch` - Batch process multiple files

**API documentation**: http://localhost:8000/docs

**Access via CLI**: `./vfw --help`

## ğŸ§ª Testing

```bash
# Test API with curl
curl -X POST http://localhost:8000/analyze \
  -F "file=@path/to/audio.wav"

# Test with CLI (recommended)
./vfw analyze path/to/audio.wav -v

# Test batch processing
./vfw batch -d ./data/sample\ database/
```
